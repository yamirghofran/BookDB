{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d5bf4d",
   "metadata": {},
   "source": [
    "## Preparing Interactions Data for Neural Collaborative Filtering Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0034458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd8ad4c",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dfae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_reduced_df = dd.read_parquet(\"data/reduced_interactions.parquet\")\n",
    "user_id_map = pd.read_csv(\"data/user_id_map.csv\")\n",
    "book_id_map = pd.read_csv(\"data/book_id_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff1688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid user IDs saved to data/reduced_user_ids.csv\n",
      "Valid book IDs saved to data/reduced_book_ids.csv\n",
      "Displaying head using Dask (memory efficient):\n",
      "                               userId    itemId  rating   timestamp\n",
      "68   8842281e1d1347389f2ab93d60773d4d   6480781       5  1490208469\n",
      "104  8842281e1d1347389f2ab93d60773d4d  29584452       4  1481655602\n",
      "117  8842281e1d1347389f2ab93d60773d4d  28119237       4  1474586352\n",
      "126  8842281e1d1347389f2ab93d60773d4d    186074       5  1490208466\n",
      "138  8842281e1d1347389f2ab93d60773d4d  15839976       5  1490208465\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Select and rename columns on the filtered Dask DataFrame\n",
    "interactions_prepared_df = interactions_reduced_df[['user_id', 'book_id', 'rating', 'date_updated']].rename(columns={\n",
    "    'user_id': 'userId',\n",
    "    'book_id': 'itemId',\n",
    "    'date_updated': 'timestamp'\n",
    "})\n",
    "\n",
    "# Convert 'timestamp' column using Dask's to_datetime\n",
    "# Use utc=True to convert parsed times (with offset from %z) directly to UTC\n",
    "interactions_prepared_df['timestamp'] = dd.to_datetime(\n",
    "    interactions_prepared_df['timestamp'],\n",
    "    format='%a %b %d %H:%M:%S %z %Y',\n",
    "    errors='coerce',\n",
    "    utc=True  # Add this argument\n",
    ")\n",
    "\n",
    "# Convert datetime objects (now timezone-aware UTC) to Unix timestamp\n",
    "# Casting timezone-aware datetime to int64 gives nanoseconds since UTC epoch\n",
    "interactions_prepared_df['timestamp'] = (interactions_prepared_df['timestamp'].astype(np.int64) // 10**9)\n",
    "\n",
    "# --- Option 1: View the head without loading all data ---\n",
    "# This is memory efficient for inspection\n",
    "print(\"Displaying head using Dask (memory efficient):\")\n",
    "print(interactions_prepared_df.head())\n",
    "\n",
    "# Persist the filtered and prepared dataframe in memory if needed for further computations\n",
    "# interactions_prepared_df = interactions_prepared_df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278c3ce",
   "metadata": {},
   "source": [
    "## Create Reduced Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ef462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced user ID mapping saved to data/user_id_map_reduced.csv. Total users: 205242\n",
      "Reduced item ID mapping saved to data/item_id_map_reduced.csv. Total items: 17663\n",
      "\n",
      "Displaying head of final DataFrame with new integer IDs:\n",
      "     userId  itemId  rating   timestamp\n",
      "68    97547    1733       5  1490208469\n",
      "104   97547   13113       4  1481655602\n",
      "117   97547   12705       4  1474586352\n",
      "126   97547    7259       5  1490208466\n",
      "138   97547     441       5  1490208465\n"
     ]
    }
   ],
   "source": [
    "# Compute unique user and item IDs from the prepared dataframe\n",
    "unique_users = interactions_prepared_df['userId'].unique().compute()\n",
    "unique_items = interactions_prepared_df['itemId'].unique().compute()\n",
    "\n",
    "# Create mappings from original IDs to new consecutive integer IDs starting from 0\n",
    "user_map = pd.Series(range(len(unique_users)), index=unique_users)\n",
    "item_map = pd.Series(range(len(unique_items)), index=unique_items)\n",
    "\n",
    "# Save the user mapping to CSV\n",
    "user_map_df = user_map.reset_index()\n",
    "user_map_df.columns = ['original_userId', 'new_userId']\n",
    "user_map_df.to_csv(\"data/user_id_map_reduced.csv\", index=False)\n",
    "print(f\"Reduced user ID mapping saved to data/user_id_map_reduced.csv. Total users: {len(user_map_df)}\")\n",
    "\n",
    "# Save the item mapping to CSV\n",
    "item_map_df = item_map.reset_index()\n",
    "item_map_df.columns = ['original_itemId', 'new_itemId']\n",
    "item_map_df.to_csv(\"data/item_id_map_reduced.csv\", index=False)\n",
    "print(f\"Reduced item ID mapping saved to data/item_id_map_reduced.csv. Total items: {len(item_map_df)}\")\n",
    "\n",
    "# Apply the mappings to the Dask DataFrame\n",
    "# Use .map() which works efficiently with a Pandas Series map\n",
    "interactions_final_df = interactions_prepared_df.copy()\n",
    "interactions_final_df['userId'] = interactions_final_df['userId'].map(user_map, meta=('userId', 'int64'))\n",
    "interactions_final_df['itemId'] = interactions_final_df['itemId'].map(item_map, meta=('itemId', 'int64'))\n",
    "\n",
    "# Verify the result (optional)\n",
    "print(\"\\nDisplaying head of final DataFrame with new integer IDs:\")\n",
    "print(interactions_final_df.head())\n",
    "\n",
    "# Persist the final dataframe if needed for further computations\n",
    "# interactions_final_df = interactions_final_df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2807213",
   "metadata": {},
   "source": [
    "## Save to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73778b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared interactions DataFrame saved to single file: data/interactions_prepared_ncf_reduced.parquet\n"
     ]
    }
   ],
   "source": [
    "# Define the output filename (ensure it ends with .parquet)\n",
    "output_filename = \"data/interactions_prepared_ncf_reduced.parquet\"\n",
    "\n",
    "# Repartition to a single partition and save to a single file\n",
    "# Use write_index=False instead of index=False\n",
    "interactions_final_df.repartition(npartitions=1).to_parquet(\n",
    "    output_filename,\n",
    "    write_index=False\n",
    ")\n",
    "\n",
    "print(f\"Prepared interactions DataFrame saved to single file: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
