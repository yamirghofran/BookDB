{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Encoder Fine-Tuning & Evaluation Notebook\n",
    "\n",
    "This notebook outlines the end-to-end process for fine-tuning a Sentence-Transformers `CrossEncoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install & Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "def download_from_r2(object_name, local_path, bucket_name=\"bookdbio\"):\n",
    "    # ensure parent dir exists\n",
    "    parent_dir = os.path.dirname(local_path)\n",
    "    if parent_dir and not os.path.isdir(parent_dir):\n",
    "        os.makedirs(parent_dir, exist_ok=True)\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "        endpoint_url = f\"https://a9a190ee80813000e18bacf626b1281b.r2.cloudflarestorage.com/\",\n",
    "        aws_access_key_id = '85fec6dd1268801ac8c1c59175ba0b76',\n",
    "        aws_secret_access_key = '798b753bab748f2c7f5e0f46fd6506b7f0b206e362b1e00055d060a72b88d55d',\n",
    "        config = Config(signature_version='s3v4')\n",
    "   )\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket_name, object_name, local_path)\n",
    "        print(f\"Successfully downloaded {object_name} to {local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed for {object_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded data/training_pairs.parquet.zip to data/training_pairs.parquet.zip\n"
     ]
    }
   ],
   "source": [
    "download_from_r2(\"data/training_pairs.parquet.zip\", \"data/training_pairs.parquet.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Define the base path to your Parquet directory\n",
    "base_path = 'data/training_pairs.parquet/' # Make sure this ends with a slash\n",
    "\n",
    "# List the specific parts you want to load\n",
    "parts_to_load = [\n",
    "    base_path + 'part.0.parquet',\n",
    "    base_path + 'part.1.parquet',\n",
    "    base_path + 'part.2.parquet',\n",
    "    base_path + 'part.3.parquet',\n",
    "    base_path + 'part.4.parquet',\n",
    "    base_path + 'part.5.parquet',\n",
    "    base_path + 'part.6.parquet',\n",
    "    base_path + 'part.7.parquet',\n",
    "    base_path + 'part.8.parquet',\n",
    "    base_path + 'part.9.parquet',\n",
    "    base_path + 'part.10.parquet',\n",
    "    base_path + 'part.11.parquet',\n",
    "    base_path + 'part.12.parquet',\n",
    "]\n",
    "\n",
    "# Load the specified parts\n",
    "df_dd = dd.read_parquet(parts_to_load)\n",
    "\n",
    "# You can then compute it to a Pandas DataFrame if needed for further processing\n",
    "# or use Dask operations directly.\n",
    "training_pairs_df = df_dd.compute()\n",
    "\n",
    "print(f\"Dask DataFrame loaded with {df_dd.npartitions} partitions.\")\n",
    "# print(df_pd.head())\n",
    "# print(f\"Shape of loaded data: {df_pd.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_ctx</th>\n",
       "      <th>book_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>57854</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Tao Te Ching | Genres: history, literat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>15808287</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Mrs. Lincoln's Dressmaker | Genres: bio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>3692</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: The Heart of the Matter | Genres: conte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>603515</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: The Hound of Rowan (The Tapestry, #1) |...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>34</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: The Fellowship of the Ring (The Lord of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>73965</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Drinking: A Love Story | Genres: biogra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>1215919</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Highlander Untamed (MacLeods of Skye Tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>218038</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: All About Love (Cynster, #6) | Genres: ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>7332</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: The Silmarillion | Genres: adventure, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>455930</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Echo Burning (Jack Reacher, #5) | Genre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>6145711</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: The Walking Dead, Vol. 10: What We Beco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>23361172</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Paperweight | Genres: contemporary, dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>5470</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: 1984 | Genres: dystopian, fantasy, horr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>343529</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: On a Wild Night (Cynster, #8) | Genres:...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>16057629</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Seducing Cinderella (Fighting for Love,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>73716</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Como agua para chocolate | Genres: cont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>9646</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Homage to Catalonia | Genres: biography...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>3077927</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: ماجدولين | Genres: drama, literature, r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>916856</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: Miss Pettigrew Lives for a Day | Genres...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>001af7947e217e17694c5a9c097afffb</td>\n",
       "      <td>14142</td>\n",
       "      <td>Favorite books: Tao Te Ching by Lao Tzu and Gi...</td>\n",
       "      <td>Title: The Art of Loving | Genres: education, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id   book_id  \\\n",
       "0   001af7947e217e17694c5a9c097afffb     57854   \n",
       "1   001af7947e217e17694c5a9c097afffb  15808287   \n",
       "2   001af7947e217e17694c5a9c097afffb      3692   \n",
       "3   001af7947e217e17694c5a9c097afffb    603515   \n",
       "4   001af7947e217e17694c5a9c097afffb        34   \n",
       "5   001af7947e217e17694c5a9c097afffb     73965   \n",
       "6   001af7947e217e17694c5a9c097afffb   1215919   \n",
       "7   001af7947e217e17694c5a9c097afffb    218038   \n",
       "8   001af7947e217e17694c5a9c097afffb      7332   \n",
       "9   001af7947e217e17694c5a9c097afffb    455930   \n",
       "10  001af7947e217e17694c5a9c097afffb   6145711   \n",
       "11  001af7947e217e17694c5a9c097afffb  23361172   \n",
       "12  001af7947e217e17694c5a9c097afffb      5470   \n",
       "13  001af7947e217e17694c5a9c097afffb    343529   \n",
       "14  001af7947e217e17694c5a9c097afffb  16057629   \n",
       "15  001af7947e217e17694c5a9c097afffb     73716   \n",
       "16  001af7947e217e17694c5a9c097afffb      9646   \n",
       "17  001af7947e217e17694c5a9c097afffb   3077927   \n",
       "18  001af7947e217e17694c5a9c097afffb    916856   \n",
       "19  001af7947e217e17694c5a9c097afffb     14142   \n",
       "\n",
       "                                             user_ctx  \\\n",
       "0   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "1   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "2   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "3   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "4   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "5   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "6   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "7   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "8   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "9   Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "10  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "11  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "12  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "13  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "14  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "15  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "16  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "17  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "18  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "19  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
       "\n",
       "                                            book_text  label  \n",
       "0   Title: Tao Te Ching | Genres: history, literat...      1  \n",
       "1   Title: Mrs. Lincoln's Dressmaker | Genres: bio...      0  \n",
       "2   Title: The Heart of the Matter | Genres: conte...      0  \n",
       "3   Title: The Hound of Rowan (The Tapestry, #1) |...      0  \n",
       "4   Title: The Fellowship of the Ring (The Lord of...      1  \n",
       "5   Title: Drinking: A Love Story | Genres: biogra...      0  \n",
       "6   Title: Highlander Untamed (MacLeods of Skye Tr...      0  \n",
       "7   Title: All About Love (Cynster, #6) | Genres: ...      0  \n",
       "8   Title: The Silmarillion | Genres: adventure, a...      1  \n",
       "9   Title: Echo Burning (Jack Reacher, #5) | Genre...      0  \n",
       "10  Title: The Walking Dead, Vol. 10: What We Beco...      0  \n",
       "11  Title: Paperweight | Genres: contemporary, dra...      0  \n",
       "12  Title: 1984 | Genres: dystopian, fantasy, horr...      1  \n",
       "13  Title: On a Wild Night (Cynster, #8) | Genres:...      0  \n",
       "14  Title: Seducing Cinderella (Fighting for Love,...      0  \n",
       "15  Title: Como agua para chocolate | Genres: cont...      0  \n",
       "16  Title: Homage to Catalonia | Genres: biography...      1  \n",
       "17  Title: ماجدولين | Genres: drama, literature, r...      0  \n",
       "18  Title: Miss Pettigrew Lives for a Day | Genres...      0  \n",
       "19  Title: The Art of Loving | Genres: education, ...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pairs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of loaded data: (2862473, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of loaded data: {training_pairs_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (936681, 5)\n",
      "\n",
      "Columns: ['user_id', 'book_id', 'user_ctx', 'book_text', 'label']\n",
      "\n",
      "Sample of the data:\n",
      "                            user_id   book_id  \\\n",
      "0  001af7947e217e17694c5a9c097afffb     57854   \n",
      "1  001af7947e217e17694c5a9c097afffb  15808287   \n",
      "2  001af7947e217e17694c5a9c097afffb      3692   \n",
      "3  001af7947e217e17694c5a9c097afffb    603515   \n",
      "4  001af7947e217e17694c5a9c097afffb        34   \n",
      "\n",
      "                                            user_ctx  \\\n",
      "0  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
      "1  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
      "2  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
      "3  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
      "4  Favorite books: Tao Te Ching by Lao Tzu and Gi...   \n",
      "\n",
      "                                           book_text  label  \n",
      "0  Title: Tao Te Ching | Genres: history, literat...      1  \n",
      "1  Title: Mrs. Lincoln's Dressmaker | Genres: bio...      0  \n",
      "2  Title: The Heart of the Matter | Genres: conte...      0  \n",
      "3  Title: The Hound of Rowan (The Tapestry, #1) |...      0  \n",
      "4  Title: The Fellowship of the Ring (The Lord of...      1  \n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "0    698112\n",
      "1    238569\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example user context:\n",
      "Favorite books: Tao Te Ching by Lao Tzu and Gia-Fu Feng and Jane English and Chungliang Al Huang and Rowena Pattee Kryder and Toinette Lippe, The Fellowship of the Ring (The Lord of the Rings, #1) by J.R.R. Tolkien and The Silmarillion by J.R.R. Tolkien and Christopher Tolkien and Ted Nasmith. Favorite genres: literature and history.\n",
      "\n",
      "Example book text:\n",
      "Title: Tao Te Ching | Genres: history, literature, mythology, nonfiction, philosophy, poetry, self-help, spiritual | Description: The Tao Te Ching, the esoteric but infinitely practical book written most probably in the sixth century B.C. by Lao Tsu, has been translated more frequently than any work except the Bible. This translation of the Chinese classic, which was first published twenty-five years ago, has sold more copies than any of the others. It offers the essence of each word and makes Lao Tsu's teaching immediate and alive.\n",
      "The philosophy of Lao Tsu is simple: Accept what is in front of you without wanting the situation to be other than it is. Study the natural order of things and work with it rather than against it, for to try to change what isonly sets up resistance. Nature provides everything without requiring payment or thanks, and also provides for all without discrimination--therefore let us present the same face to everyone and treat all men as equals, however they may behave. If we watch carefully, we will see that work proceeds more quickly and easily if we stop \"trying,\" if we stop putting in so much extra effort, if we stop looking for results. In the clarity of a still and open mind, truth will be reflected. We will come to appreciate the original meaning of the word \"understand,\" which means \"to stand under.\" We serve whatever or whoever stands before us, without any thought for ourselves. Te--which may be translated as \"virtue\" or \"strength\"--lies always in Tao,or\" natural law. In other words: Simply be. | Authors: Lao Tzu, Gia-Fu Feng, Jane English, Chungliang Al Huang, Rowena Pattee Kryder, Toinette Lippe\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Load the training pairs\n",
    "training_pairs = dd.read_parquet('data/training_pairs.parquet/part.0.parquet')\n",
    "\n",
    "# Convert to pandas for easier inspection\n",
    "training_pairs_pd = training_pairs.compute()\n",
    "\n",
    "# Display basic information\n",
    "print(\"Shape of the dataset:\", training_pairs_pd.shape)\n",
    "print(\"\\nColumns:\", training_pairs_pd.columns.tolist())\n",
    "print(\"\\nSample of the data:\")\n",
    "print(training_pairs_pd.head())\n",
    "\n",
    "# Check the distribution of labels\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(training_pairs_pd['label'].value_counts())\n",
    "\n",
    "# Check some example user contexts and book texts\n",
    "print(\"\\nExample user context:\")\n",
    "print(training_pairs_pd['user_ctx'].iloc[0])\n",
    "print(\"\\nExample book text:\")\n",
    "print(training_pairs_pd['book_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of positive examples per user:\n",
      "user_id\n",
      "0005f52944ea1992e95d61f287acaea9     65\n",
      "0006260f85929db85eddee3a0bd0e504     20\n",
      "0006db397ebf02b2e891d1048fb70dbc    166\n",
      "0006de2967df1ec4432c51090803966e     76\n",
      "000883382802f2d95a3dd545bb953882    154\n",
      "                                   ... \n",
      "1d364492146d00ceebf9b7ec4e7d45af    298\n",
      "1d4a2185b490d26a3ab0faedc4adf6c7     42\n",
      "1d6a5b005de5e4c27945dca1c13d47f2    121\n",
      "1de44842d3080ec55181e46b0cf16ed1     78\n",
      "1dfed2c58f01fe899666bd9a6ce319e1    155\n",
      "Length: 5357, dtype: int64\n",
      "\n",
      "Statistics about positive examples per user:\n",
      "count    5357.000000\n",
      "mean      136.083816\n",
      "std       101.274552\n",
      "min         1.000000\n",
      "25%        77.000000\n",
      "50%       109.000000\n",
      "75%       165.000000\n",
      "max      1478.000000\n",
      "dtype: float64\n",
      "\n",
      "Number of users with less than 5 positive examples: 30\n",
      "\n",
      "Example users with few positives:\n",
      "user_id\n",
      "008c374625966c32477ebab37e835a4e    1\n",
      "00e8157279aa30f4b919aea0a887f49a    2\n",
      "01e2d286d0361edf8c62bc580d3baa18    1\n",
      "02ac01d9ebc7165e80d8967f075adbd3    3\n",
      "0378ae8905e15ae09e01cad7c307a78b    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count positive labels per user\n",
    "positive_counts = training_pairs_df[training_pairs_df['label'] == 1].groupby('user_id').size()\n",
    "print(\"\\nNumber of positive examples per user:\")\n",
    "print(positive_counts)\n",
    "\n",
    "# Get some statistics about the positive counts\n",
    "print(\"\\nStatistics about positive examples per user:\")\n",
    "print(positive_counts.describe())\n",
    "\n",
    "# Find users with very few positive examples\n",
    "users_with_few_positives = positive_counts[positive_counts < 5]\n",
    "print(f\"\\nNumber of users with less than 5 positive examples: {len(users_with_few_positives)}\")\n",
    "print(\"\\nExample users with few positives:\")\n",
    "print(users_with_few_positives.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ArrowStringArray>\n",
      "['001af7947e217e17694c5a9c097afffb', '0006260f85929db85eddee3a0bd0e504',\n",
      " '000bcda59ab565512f51f9e1f531b5e5', '0005f52944ea1992e95d61f287acaea9',\n",
      " '000883382802f2d95a3dd545bb953882', '0006db397ebf02b2e891d1048fb70dbc',\n",
      " '0009b61b9879bb2e5b84ce24f43450c8', '00281bdc3b8dd584ca6c5cb867de959f',\n",
      " '0006de2967df1ec4432c51090803966e', '002c10ebc541a4303b4d2c0aa2bff335',\n",
      " ...\n",
      " '090ebce33f677e84d5ee0e8510996a15', '093a06eb1563ef6d2a6c443b5189db47',\n",
      " '0a97f788f5707a7f116f5cc16875597e', '0951f343eed8911a4451ae2fa80dc1f3',\n",
      " '08c70632f3c4ca2793d221f9d47037fb', '096eb5757df185c7793fac23085a5b62',\n",
      " '08c0a7ae8992a65d7792dd9c69b41369', '090fd9cea80dbfb06cf11885af8a1e38',\n",
      " '093ef1f64c3baa83e54d9e63a550369d', '089c7ad67ccf2f81c8dc476db53f3235']\n",
      "Length: 1785, dtype: string\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Get all unique user IDs\n",
    "user_ids = training_pairs_pd['user_id'].unique()\n",
    "\n",
    "print(user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (2862473, 5)\n",
      "Number of positive samples after filtering/sampling: 16017\n",
      "Number of unique users after filtering/sampling positives: 5339\n",
      "Final processed DataFrame shape: (64068, 5)\n",
      "Label distribution in final DataFrame:\n",
      "label\n",
      "0    0.75\n",
      "1    0.25\n",
      "Name: proportion, dtype: float64\n",
      "Number of unique users in final DataFrame: 5339\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Assuming 'df' is your DataFrame loaded with pd.read_parquet(data_path)\n",
    "# and has columns: 'user_id', 'label', 'user_ctx', 'book_text'\n",
    "\n",
    "# --- Configuration ---\n",
    "MIN_POSITIVES_TO_KEEP_USER = 3\n",
    "MAX_POSITIVES_TO_SAMPLE = 3  # Changed from 10 to 3\n",
    "NEGATIVES_PER_POSITIVE = 3\n",
    "RANDOM_SEED = 42 # For reproducibility\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "print(f\"Original DataFrame shape: {training_pairs_df.shape}\")\n",
    "\n",
    "# --- Step 1: Identify positive and negative interactions ---\n",
    "df_positives = training_pairs_df[training_pairs_df['label'] == 1]\n",
    "df_negatives = training_pairs_df[training_pairs_df['label'] == 0]\n",
    "\n",
    "# --- Step 2: Process each user ---\n",
    "selected_positive_samples = []\n",
    "users_to_process = df_positives['user_id'].unique()\n",
    "\n",
    "for user_id in users_to_process:\n",
    "    user_positive_df = df_positives[df_positives['user_id'] == user_id]\n",
    "    num_user_positives = len(user_positive_df)\n",
    "\n",
    "    if num_user_positives >= MAX_POSITIVES_TO_SAMPLE:\n",
    "        # If >= 3 positives, sample 3\n",
    "        selected_positive_samples.append(user_positive_df.sample(n=MAX_POSITIVES_TO_SAMPLE, random_state=RANDOM_SEED))\n",
    "    elif num_user_positives >= MIN_POSITIVES_TO_KEEP_USER:\n",
    "        # If exactly 3 positives, keep them all\n",
    "        selected_positive_samples.append(user_positive_df)\n",
    "    # Else (less than 3 positives), drop the user (do nothing here)\n",
    "\n",
    "# Combine all selected positive samples\n",
    "if selected_positive_samples:\n",
    "    final_positives_df = pd.concat(selected_positive_samples).reset_index(drop=True)\n",
    "else:\n",
    "    final_positives_df = pd.DataFrame(columns=df.columns) # Empty DataFrame if no users meet criteria\n",
    "\n",
    "print(f\"Number of positive samples after filtering/sampling: {len(final_positives_df)}\")\n",
    "print(f\"Number of unique users after filtering/sampling positives: {final_positives_df['user_id'].nunique()}\")\n",
    "\n",
    "# --- Step 3: Sample negatives for each selected positive ---\n",
    "final_samples_list = []\n",
    "if not final_positives_df.empty:\n",
    "    for _, positive_row in final_positives_df.iterrows():\n",
    "        user_id = positive_row['user_id']\n",
    "        \n",
    "        # Add the positive sample\n",
    "        final_samples_list.append(positive_row.to_dict())\n",
    "        \n",
    "        # Get all negative samples for this user\n",
    "        user_negative_df = df_negatives[df_negatives['user_id'] == user_id]\n",
    "        \n",
    "        if not user_negative_df.empty:\n",
    "            num_negs_to_sample = min(NEGATIVES_PER_POSITIVE, len(user_negative_df))\n",
    "            if num_negs_to_sample > 0:\n",
    "                sampled_negatives = user_negative_df.sample(n=num_negs_to_sample, random_state=RANDOM_SEED)\n",
    "                for _, neg_row in sampled_negatives.iterrows():\n",
    "                    final_samples_list.append(neg_row.to_dict())\n",
    "\n",
    "# Create the final DataFrame\n",
    "processed_df = pd.DataFrame(final_samples_list)\n",
    "\n",
    "if not processed_df.empty:\n",
    "    # Ensure correct dtypes, especially for label\n",
    "    processed_df['label'] = processed_df['label'].astype(int)\n",
    "    print(f\"Final processed DataFrame shape: {processed_df.shape}\")\n",
    "    print(f\"Label distribution in final DataFrame:\\n{processed_df['label'].value_counts(normalize=True)}\")\n",
    "    print(f\"Number of unique users in final DataFrame: {processed_df['user_id'].nunique()}\")\n",
    "else:\n",
    "    print(\"No samples met the criteria. The processed DataFrame is empty.\")\n",
    "\n",
    "# Now, 'processed_df' is your new DataFrame. You can then split this into train/test.\n",
    "# For example:\n",
    "# users = processed_df['user_id'].unique()\n",
    "# train_users, test_users = train_test_split(users, test_size=test_size, random_state=random_seed)\n",
    "# train_df = processed_df[processed_df['user_id'].isin(train_users)].reset_index(drop=True)\n",
    "# test_df  = processed_df[processed_df['user_id'].isin(test_users)].reset_index(drop=True)\n",
    "# print(f\"Train pairs: {len(train_df)}, Test pairs: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path = 'data/training_pairs.parquet'\n",
    "output_model_dir = \n",
    "\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "warmup_steps = 100\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Load all pairs and drop book_id\n",
    "df = pd.read_parquet(data_path)\n",
    "df = df.drop('book_id', axis=1)\n",
    "\n",
    "# 2) Get unique users\n",
    "users = df['user_id'].unique()\n",
    "\n",
    "# 3) First split: 80% train, 20% temp (val+test)\n",
    "train_users, temp_users = train_test_split(\n",
    "    users, \n",
    "    test_size=0.2, \n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# 4) Second split: half of temp → val (10%), half → test (10%)\n",
    "val_users, test_users = train_test_split(\n",
    "    temp_users, \n",
    "    test_size=0.5, \n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# 5) Build DataFrames\n",
    "train_df = df[df['user_id'].isin(train_users)].reset_index(drop=True)\n",
    "val_df   = df[df['user_id'].isin(val_users)].reset_index(drop=True)\n",
    "test_df  = df[df['user_id'].isin(test_users)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train pairs: {len(train_df)}, Val pairs: {len(val_df)}, Test pairs: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare InputExamples & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to InputExample\n",
    "train_examples = [\n",
    "    InputExample(texts=[row.user_ctx, row.book_text], label=float(row.label))\n",
    "    for row in train_df.itertuples()\n",
    "]\n",
    "\n",
    "val_examples = [\n",
    "    InputExample(texts=[row.user_ctx, row.book_text], label=float(row.label))\n",
    "    for row in val_df.itertuples()\n",
    "]\n",
    "\n",
    "test_examples = [\n",
    "    InputExample(texts=[row.user_ctx, row.book_text], label=float(row.label))\n",
    "    for row in test_df.itertuples()\n",
    "]\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "val_dataloader   = DataLoader(val_examples, shuffle=False, batch_size=batch_size)\n",
    "test_dataloader  = DataLoader(test_examples, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Validation Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instantiate & Fine-Tune CrossEncoder\n",
    "\n",
    "cross-encoder/ms-marco-MiniLM-L-6-v2 is a 6-layer MiniLM distilled into a cross-encoder architecture and pretrained on the MS MARCO passage ranking task. It takes a paired input (e.g. user context + book text) and produces a single relevance score via full token-level attention.\n",
    "\n",
    "Justification\n",
    "\t•\tRanking-Tuned Pretraining\n",
    "Its MS MARCO heritage means it already knows how to judge fine-grained relevance patterns—crucial for matching nuanced book descriptions to user tastes.\n",
    "\t•\tSpeed-Quality Sweet Spot\n",
    "At ~60 MB and with inference under 15 ms per candidate, it delivers ~90–95 % of full BERT-base accuracy, keeping end-to-end latency low.\n",
    "\t•\tEfficient Fine-Tuning\n",
    "Requires only 2–3 epochs over ~150 K (user,book) pairs to adapt deeply to book-domain language, making rapid iteration feasible.\n",
    "\t•\tCompact & Deployable\n",
    "Its small footprint simplifies packaging, loading, and scaling in production environments with moderate memory and compute budgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "model = CrossEncoder(\n",
    "    'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "    num_labels=1,\n",
    "    max_length=256,\n",
    "    loss_fct='cross_entropy'  \n",
    ")\n",
    "\n",
    "\n",
    "from sentence_transformers.evaluation import CrossEncoderEvaluator\n",
    "\n",
    "evaluator = CrossEncoderEvaluator.from_input_examples(\n",
    "    val_examples,     # list of InputExample for validation\n",
    "    name='val',\n",
    "    batch_size=batch_size,\n",
    "    main_score_function=lambda y_true, y_pred: ndcg_score([y_true], [y_pred], k=3)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluator=evaluator,\n",
    "    evaluation_steps=len(train_dataloader),  # run eval once per epoch\n",
    "    early_stopping=True,\n",
    "    use_amp=True,             # alias for fp16 in newer versions\n",
    "    output_path=output_model_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test pairs for prediction\n",
    "test_pairs = [[row.user_ctx, row.book_text] for row in test_df.itertuples()]\n",
    "scores = model.predict(test_pairs)\n",
    "labels = test_df['label'].values\n",
    "\n",
    "# Compute metrics\n",
    "auc = roc_auc_score(labels, scores)\n",
    "ap = average_precision_score(labels, scores)\n",
    "ndcg = ndcg_score([labels], [scores], k=10)\n",
    "\n",
    "print(f\"ROC AUC: {auc:.4f}\")\n",
    "print(f\"Average Precision: {ap:.4f}\")\n",
    "print(f\"NDCG@10: {ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save & Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is already saved during fit\n",
    "# To load:\n",
    "from sentence_transformers import CrossEncoder\n",
    "loaded_model = CrossEncoder(output_model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a single user and its candidates\n",
    "user_ctx = \"Favorite books: ...\"  # fetched or precomputed\n",
    "candidate_texts = [\"Title: ... Description: ...\", ...]\n",
    "pairs = [[user_ctx, txt] for txt in candidate_texts]\n",
    "scores = loaded_model.predict(pairs)\n",
    "\n",
    "# Rerank\n",
    "candidates = ['book1', 'book2', ...]\n",
    "ranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)\n",
    "print(ranked[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
