{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook demonstrates the entire recommendation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_user_id = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Data and Create Book Library and User Library\n",
    "\n",
    "In the actual pipeline this is not necessary as we have databases setup, but for the purpose of this demo and experimentation we need load these sets localy into the notebook to create a user library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "def download_from_r2(object_name, local_path, bucket_name=\"bookdbio\"):\n",
    "    # ensure parent dir exists\n",
    "    parent_dir = os.path.dirname(local_path)\n",
    "    if parent_dir and not os.path.isdir(parent_dir):\n",
    "        os.makedirs(parent_dir, exist_ok=True)\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "        endpoint_url = f\"https://a9a190ee80813000e18bacf626b1281b.r2.cloudflarestorage.com/\",\n",
    "        aws_access_key_id = '85fec6dd1268801ac8c1c59175ba0b76',\n",
    "        aws_secret_access_key = '798b753bab748f2c7f5e0f46fd6506b7f0b206e362b1e00055d060a72b88d55d',\n",
    "        config = Config(signature_version='s3v4')\n",
    "   )\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket_name, object_name, local_path)\n",
    "        print(f\"Successfully downloaded {object_name} to {local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed for {object_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_bucket_contents(bucket_name=\"bookdbio\"):\n",
    "    \"\"\"List all objects in the R2 bucket\"\"\"\n",
    "    s3 = boto3.client('s3',\n",
    "        endpoint_url = f\"https://a9a190ee80813000e18bacf626b1281b.r2.cloudflarestorage.com/\",\n",
    "        aws_access_key_id = '85fec6dd1268801ac8c1c59175ba0b76',\n",
    "        aws_secret_access_key = '798b753bab748f2c7f5e0f46fd6506b7f0b206e362b1e00055d060a72b88d55d',\n",
    "        config = Config(signature_version='s3v4')\n",
    "   )\n",
    "    \n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            print(\"Available files in bucket:\")\n",
    "            for obj in response['Contents']:\n",
    "                print(f\"- {obj['Key']}\")\n",
    "        else:\n",
    "            print(\"Bucket is empty\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing bucket contents: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import books_df\n",
    "\n",
    "Contains book metadata for complete library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_from_r2(\"data/reduced_books.parquet\", \"data/reduced_books.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = dd.read_parquet(\"data/reduced_books.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import reduced_interactions\n",
    "\n",
    "Reduced set of interactions: contains information about a users interaction with a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded data/reduced_interactions.parquet to data/reduced_interactions.parquet\n"
     ]
    }
   ],
   "source": [
    "download_from_r2(\"data/reduced_interactions.parquet\", \"data/reduced_interactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_df = dd.read_parquet(\"data/reduced_interactions.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import authors\n",
    "\n",
    "Used to create complete book information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_from_r2(\"data/new_authors.parquet\", \"data/new_authors.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = dd.read_parquet(\"data/new_authors.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Adding Authors and Extracting Genres to Improve Books Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_genres(popular_shelves):\n",
    "    \"\"\"\n",
    "    Extracts potential genres from a list of popular shelves dictionaries,\n",
    "    adding only the base genre keyword found.\n",
    "\n",
    "    Args:\n",
    "        popular_shelves: A list of dictionaries, where each dictionary has\n",
    "                         'count' and 'name' keys.\n",
    "\n",
    "    Returns:\n",
    "        A list of unique base genre names found, or an empty list on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(popular_shelves, np.ndarray) or len(popular_shelves) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Use a set to store unique base genres found\n",
    "        found_genres = set() \n",
    "        \n",
    "        genre_keywords = [\n",
    "            'action', 'adventure', 'comedy', 'crime', 'mystery', 'textbook', 'children', 'mathematics', 'fantasy',\n",
    "            'historical', 'horror', 'romance', 'satire', 'science fiction',\n",
    "            'scifi', 'speculative fiction', 'thriller', 'western', 'paranormal',\n",
    "            'dystopian', 'urban fantasy', 'contemporary', 'young adult', 'ya',\n",
    "            'middle grade', 'children\\'s', 'literary fiction', 'magic realism',\n",
    "            'historical fiction', 'gothic', 'suspense', 'biography', 'memoir',\n",
    "            'nonfiction', 'poetry', 'drama', 'historical romance',\n",
    "            'fantasy romance', 'romantic suspense', 'science fiction romance',\n",
    "            'contemporary romance', 'paranormal romance', 'epic fantasy',\n",
    "            'dark fantasy', 'sword and sorcery', 'steampunk', 'cyberpunk',\n",
    "            'apocalyptic', 'post-apocalyptic', 'alternate history',\n",
    "            'superhero', 'mythology', 'fairy tales', 'folklore', 'war',\n",
    "            'military fiction', 'spy fiction', 'political fiction', 'social science fiction',\n",
    "            'techno-thriller', 'medical thriller', 'legal thriller',\n",
    "            'psychological thriller', 'cozy mystery', 'hardboiled', 'noir',\n",
    "            'coming-of-age', 'lgbtq+', 'christian fiction', 'religious fiction',\n",
    "            'humor', 'travel', 'food', 'cooking', 'health', 'self-help',\n",
    "            'business', 'finance', 'history', 'science', 'technology', 'nature',\n",
    "            'art', 'music', 'philosophy', 'education', 'true crime', 'spiritual',\n",
    "            'anthology', 'short stories', 'plays', 'screenplays', 'graphic novel',\n",
    "            'comics', 'manga', 'erotica', 'new adult', 'chick lit', 'womens fiction',\n",
    "            'sports fiction', 'family saga', ' Regency romance', 'literature'\n",
    "        ]\n",
    "        # Sort keywords by length descending to match longer phrases first (e.g., \"science fiction\" before \"science\")\n",
    "        genre_keywords.sort(key=len, reverse=True)\n",
    "\n",
    "        ignore_keywords = ['to-read', 'owned', 'hardcover', 'shelfari-favorites', 'series', 'might-read',\n",
    "                           'dnf-d', 'hambly-barbara', 'strong-females', 'first-in-series',\n",
    "                           'no-thanks-series-collections-boxes', 'entertaining-but-limited',\n",
    "                           'kate-own', 'e-book', 'compliation', 'my-books',\n",
    "                           'books-i-own-but-have-not-read', 'everything-owned', 'books-to-find',\n",
    "                           'i-own-it', 'favorite', 'not-read', 'read-some-day', 'library',\n",
    "                           'audiobooks', 'status-borrowed', 'owned-books',\n",
    "                           'spec-fic-awd-locus-nom', '01', 'hardbacks', 'paper', 'german',\n",
    "                           'hardback', 'physical-scifi-fantasy', 'childhood-favorites',\n",
    "                           'bundle-same-author', 'aa-sifi-fantasy', 'ready-to-read',\n",
    "                           'bought-on-flee-markets', 'fantasy-general', 'hardcopy', 'box-2',\n",
    "                           'unfinished', 'magic', 'duplicates', 'favorites', 'books-i-own',\n",
    "                           'fantasy-classic', 'own-hard-copy', 'fantasy-read',\n",
    "                           'book-club-edition', 'sci-fi-or-fantasy', 'fiction-fantasy',\n",
    "                           'fiction-literature-poetry', 'paused-hiatus', 'status—borrowed',\n",
    "                           'recs-fantasy', 'fantasy-scifi', 'omnibus', 'speculative',\n",
    "                           'sf--fantasy', 'in-my-home-library', 'fant-myth-para-vamps',\n",
    "                           'read-in-my-20s']\n",
    "\n",
    "        for shelf in popular_shelves:\n",
    "            if not isinstance(shelf, dict) or 'name' not in shelf:\n",
    "                continue\n",
    "            \n",
    "            shelf_name = shelf['name'].lower().strip() # Normalize shelf name\n",
    "\n",
    "            # Skip if shelf name contains any ignore keywords\n",
    "            if any(ignore in shelf_name for ignore in ignore_keywords):\n",
    "                continue\n",
    "\n",
    "            # Check if any genre keyword is present in the shelf name\n",
    "            for keyword in genre_keywords:\n",
    "                # Use word boundaries or careful checks to avoid partial matches (e.g., 'art' in 'heart')\n",
    "                # Simple substring check for now, might need refinement depending on data\n",
    "                if keyword in shelf_name: \n",
    "                    found_genres.add(keyword) # Add the base keyword\n",
    "                    # Optional: break here if you only want the first/longest match per shelf\n",
    "                    # break \n",
    "\n",
    "        return sorted(list(found_genres))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_genres function: {e}\")\n",
    "        # Log the error message\n",
    "        logging.error(\"Error in extract_genres function\", exc_info=True)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anze/Documents/University/Y2S2/AI Machine Learning Foundations/Final Project/.venv/lib/python3.13/site-packages/dask/dataframe/dask_expr/_collection.py:4392: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('popular_shelves', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "/Users/anze/Documents/University/Y2S2/AI Machine Learning Foundations/Final Project/.venv/lib/python3.13/site-packages/dask/dataframe/dask_expr/_collection.py:4392: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('authors', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of reduced books DataFrame:\n",
      "      book_id                                              title  \\\n",
      "3     6066819                               Best Friends Forever   \n",
      "15      89375  90 Minutes in Heaven: A True Story of Death an...   \n",
      "479  11731782                              Collide (Collide, #1)   \n",
      "583     54270                                         Mein Kampf   \n",
      "807     38568                         A Quick Bite (Argeneau #1)   \n",
      "\n",
      "                                           description  \\\n",
      "3    Addie Downs and Valerie Adler were eight when ...   \n",
      "15   As he is driving home from a minister's confer...   \n",
      "479  Sherry has always known there was something ou...   \n",
      "583  Madman, tyrant, animal - history has given Ado...   \n",
      "807  That hot guy tied to Lissianna Argeneau's bed?...   \n",
      "\n",
      "                                                 genre  \\\n",
      "3    coming-of-age,contemporary,drama,humor,mystery...   \n",
      "15     biography,memoir,nonfiction,self-help,spiritual   \n",
      "479  contemporary,dystopian,fantasy,paranormal,roma...   \n",
      "583  art,biography,historical,history,horror,litera...   \n",
      "807  comedy,contemporary,erotica,fantasy,humor,para...   \n",
      "\n",
      "                     authors  \n",
      "3            Jennifer Weiner  \n",
      "15   Don Piper,Cecil Murphey  \n",
      "479             Shelly Crane  \n",
      "583             Adolf Hitler  \n",
      "807             Lynsay Sands  \n",
      "\n",
      "Genre distribution:\n",
      "Dask Series Structure:\n",
      "npartitions=1\n",
      "    int64\n",
      "      ...\n",
      "Dask Name: valuecounts, 12 expressions\n",
      "Expr=(ExplodeSeries(frame=Apply(frame=(Assign(frame=Assign(frame=ReadParquetFSSpec(6d88a7c)[['book_id', 'title', 'description']])))['genre'], function=<function <lambda> at 0x301d6d080>))).valuecounts(split_out=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anze/Documents/University/Y2S2/AI Machine Learning Foundations/Final Project/.venv/lib/python3.13/site-packages/dask/dataframe/dask_expr/_collection.py:4392: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('genre', 'object'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "# Create reduced DataFrame\n",
    "reduced_books_df = books_df[['book_id', 'title', 'description']].copy()\n",
    "\n",
    "# Modify extract_genres to return a string instead of a list\n",
    "def extract_genres_string(shelves):\n",
    "    genres = extract_genres(shelves)\n",
    "    return ','.join(genres) if genres else ''\n",
    "\n",
    "# Apply the modified function to get string representation of genres\n",
    "reduced_books_df['genre'] = books_df['popular_shelves'].apply(extract_genres_string)\n",
    "\n",
    "# Convert authors to string representation as well\n",
    "def get_author_names(author_ids):\n",
    "    author_names = []\n",
    "    for author_id in author_ids:\n",
    "        try:\n",
    "            name = authors_df.loc[authors_df['author_id'] == author_id]['name'].compute().values[0]\n",
    "            author_names.append(name)\n",
    "        except:\n",
    "            continue\n",
    "    return ','.join(author_names)\n",
    "\n",
    "reduced_books_df['authors'] = books_df['authors'].apply(get_author_names)\n",
    "\n",
    "# Display sample of the reduced DataFrame\n",
    "print(\"\\nSample of reduced books DataFrame:\")\n",
    "print(reduced_books_df.head())\n",
    "\n",
    "# Display genre distribution (need to split the strings for counting)\n",
    "print(\"\\nGenre distribution:\")\n",
    "genre_counts = reduced_books_df['genre'].apply(lambda x: x.split(',') if x else []).explode().value_counts()\n",
    "print(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Creating User Library\n",
    "def get_user_library(user_id: str, interactions_df: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get all book IDs associated with a specific user from the interactions DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        user_id: The ID of the user to get books for (as string)\n",
    "        interactions_df: DataFrame containing user-book interactions with columns 'user_id' and 'book_id'\n",
    "        \n",
    "    Returns:\n",
    "        List of book IDs that the user has interacted with\n",
    "    \"\"\"\n",
    "    # Filter interactions for the specific user and get their book IDs\n",
    "    user_books = interactions_df[interactions_df['user_id'] == user_id]['book_id'].tolist()\n",
    "    return user_books\n",
    "\n",
    "chosen_user_library = get_user_library(chosen_user_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Candidates Using Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_path = \"../embeddings/gmf_user_embeddings.parquet\"\n",
    "book_embeddings_path = \"../embeddings/gmf_book_embeddings.parquet\"\n",
    "sbert_embeddings_path = \"../embeddings/SBERT_embeddings.parquet\"\n",
    "\n",
    "user_embeddings_df = pd.read_parquet(user_embeddings_path)\n",
    "book_embeddings_df = pd.read_parquet(book_embeddings_path)\n",
    "sbert_embeddings_df = pd.read_parquet(sbert_embeddings_path)\n",
    "\n",
    "user_embeddings_df['user_id'] = user_embeddings_df['user_id'].astype(int)\n",
    "book_embeddings_df['item_id'] = book_embeddings_df['item_id'].astype(int)\n",
    "\n",
    "# Store GMF embedding column names\n",
    "gmf_embedding_cols = [str(i) for i in range(32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking based on NCF\n",
    "\n",
    "Return NCF Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gmf_ranking(user_id: str, \n",
    "                   user_embeddings_df: pd.DataFrame,\n",
    "                   book_embeddings_df: pd.DataFrame,\n",
    "                   k: int = 250) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate book recommendations using only GMF embeddings.\n",
    "    \n",
    "    Args:\n",
    "        user_id: The user ID to get recommendations for\n",
    "        user_embeddings_df: DataFrame containing user embeddings\n",
    "        book_embeddings_df: DataFrame containing book embeddings\n",
    "        k: Number of recommendations to return (default 10)\n",
    "        \n",
    "    Returns:\n",
    "        List of recommended book IDs\n",
    "    \"\"\"\n",
    "    # Convert user_id to int\n",
    "    user_id_int = int(user_id)\n",
    "    \n",
    "    # Get user embedding\n",
    "    user_row = user_embeddings_df[user_embeddings_df['user_id'] == user_id_int]\n",
    "    if len(user_row) == 0:\n",
    "        raise ValueError(f\"No embedding found for user {user_id}\")\n",
    "    \n",
    "    # Get embedding columns (assuming they're named 0-31)\n",
    "    embedding_cols = [str(i) for i in range(32)]\n",
    "    user_emb = user_row[embedding_cols].iloc[0].values.tolist()\n",
    "    \n",
    "    # Get all book embeddings\n",
    "    book_scores = []\n",
    "    for _, book_row in book_embeddings_df.iterrows():\n",
    "        book_id = str(book_row['item_id'])\n",
    "        book_emb = book_row[embedding_cols].values.tolist()\n",
    "        \n",
    "        # Compute score using dot product\n",
    "        score = np.dot(user_emb, book_emb)\n",
    "        if not (np.isnan(score) or np.isinf(score)):\n",
    "            book_scores.append((book_id, score))\n",
    "    \n",
    "    # Sort by score in descending order and return top k\n",
    "    book_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [book_id for book_id, _ in book_scores[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 GMF recommendations for user 12345:\n",
      "['12042.0', '10774.0', '1085.0', '13668.0', '8733.0', '2741.0', '16184.0', '7894.0', '8269.0', '14932.0', '5702.0', '4869.0', '9947.0', '6569.0', '7002.0', '4048.0', '11636.0', '3459.0', '10186.0', '2596.0', '11635.0', '14367.0', '10185.0', '15617.0', '934.0', '17007.0', '16462.0', '16461.0', '933.0', '5207.0', '3603.0', '6417.0', '13945.0', '5977.0', '9410.0', '8676.0', '17006.0', '1865.0', '1349.0', '6418.0', '10184.0', '935.0', '8677.0', '8678.0', '16162.0', '5123.0', '7500.0', '3137.0', '588.0', '15742.0', '4870.0', '6502.0', '9700.0', '4590.0', '9794.0', '13615.0', '8270.0', '14706.0', '8076.0', '1350.0', '17637.0', '17180.0', '13035.0', '11609.0', '16136.0', '2184.0', '11664.0', '8570.0', '10773.0', '4236.0', '12011.0', '9177.0', '11782.0', '12686.0', '16946.0', '10940.0', '9717.0', '4019.0', '1060.0', '16241.0', '675.0', '9508.0', '2786.0', '13336.0', '422.0', '1771.0', '3338.0', '6972.0', '4433.0', '6544.0', '2645.0', '9332.0', '13534.0', '17326.0', '4405.0', '12346.0', '11569.0', '10310.0', '936.0', '12636.0', '7771.0', '12508.0', '866.0', '5688.0', '2119.0', '7435.0', '9448.0', '17614.0', '2185.0', '13190.0', '3577.0', '8571.0', '2099.0', '6615.0', '3832.0', '1059.0', '10750.0', '5827.0', '4260.0', '4246.0', '5044.0', '6570.0', '12145.0', '7831.0', '971.0', '15733.0', '9928.0', '10655.0', '7682.0', '3138.0', '14061.0', '12874.0', '5978.0', '6974.0', '9101.0', '10221.0', '15660.0', '13715.0', '7926.0', '7610.0', '9795.0', '12771.0', '1205.0', '15310.0', '11282.0', '17096.0', '10306.0', '13866.0', '1720.0', '9334.0', '5850.0', '7611.0', '1770.0', '9923.0', '5494.0', '2043.0', '9333.0', '6788.0', '17127.0', '4049.0', '16555.0', '347.0', '2141.0', '11420.0', '15148.0', '13299.0', '5851.0', '2525.0', '11581.0', '7139.0', '7120.0', '16864.0', '381.0', '15031.0', '6543.0', '12260.0', '4576.0', '16011.0', '4097.0', '3315.0', '17176.0', '132.0', '15059.0', '13263.0', '13387.0', '11383.0', '9916.0', '16823.0', '12982.0', '14324.0', '14178.0', '6845.0', '1610.0', '17647.0', '8090.0', '8857.0', '10903.0', '12854.0', '15377.0', '5878.0', '5399.0', '10077.0', '12997.0', '16550.0', '8033.0', '15273.0', '1332.0', '11353.0', '140.0', '15058.0', '782.0', '15223.0', '2292.0', '11730.0', '5402.0', '17112.0', '4967.0', '4139.0', '15029.0', '11324.0', '11415.0', '8214.0', '3834.0', '10602.0', '8841.0', '16551.0', '9684.0', '822.0', '8213.0', '10920.0', '17061.0', '5377.0', '13985.0', '784.0', '14214.0', '14791.0', '4020.0', '14894.0', '1438.0', '16338.0', '17150.0', '12668.0', '11599.0', '6250.0', '5841.0', '15855.0', '805.0', '736.0', '3448.0', '10937.0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ncf_recommendations = get_gmf_ranking(\n",
    "    user_id=chosen_user_id,\n",
    "    user_embeddings_df=user_embeddings_df,\n",
    "    book_embeddings_df=book_embeddings_df,\n",
    "    k=250\n",
    ")\n",
    "\n",
    "print(\"Top 10 GMF recommendations for user 12345:\")\n",
    "print(ncf_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking based on SBERT\n",
    "\n",
    "Return SBERT Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbert_recommendations(\n",
    "    user_library: List[str],\n",
    "    book_embeddings_df: pd.DataFrame,\n",
    "    sbert_embeddings_df: pd.DataFrame,\n",
    "    k: int = 250\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Get book recommendations based on cosine similarity between user's library and other books.\n",
    "    \n",
    "    Args:\n",
    "        user_library: List of book IDs in user's library\n",
    "        book_embeddings_df: DataFrame containing book metadata\n",
    "        sbert_embeddings_df: DataFrame containing SBERT embeddings\n",
    "        k: Number of recommendations to return\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples (book_id, similarity_score)\n",
    "    \"\"\"\n",
    "    # Get all book IDs excluding user's library\n",
    "    all_book_ids = sbert_embeddings_df['book_id'].tolist()\n",
    "    candidate_book_ids = [bid for bid in all_book_ids if str(bid) not in user_library]\n",
    "    \n",
    "    # Get embeddings for user's library books\n",
    "    library_embeddings = []\n",
    "    for book_id in user_library:\n",
    "        book_row = sbert_embeddings_df[sbert_embeddings_df['book_id'] == book_id]\n",
    "        if not book_row.empty:\n",
    "            # Get embedding columns (assuming they're named 0-31)\n",
    "            embedding_cols = [str(i) for i in range(32)]\n",
    "            embedding = book_row[embedding_cols].iloc[0].values\n",
    "            library_embeddings.append(embedding)\n",
    "    \n",
    "    if not library_embeddings:\n",
    "        return []\n",
    "    \n",
    "    # Compute average library embedding\n",
    "    avg_library_embedding = np.mean(library_embeddings, axis=0)\n",
    "    \n",
    "    # Compute similarity scores for candidate books\n",
    "    scores = {}\n",
    "    for book_id in candidate_book_ids:\n",
    "        book_row = sbert_embeddings_df[sbert_embeddings_df['book_id'] == book_id]\n",
    "        if not book_row.empty:\n",
    "            # Get embedding columns\n",
    "            embedding_cols = [str(i) for i in range(32)]\n",
    "            book_embedding = book_row[embedding_cols].iloc[0].values\n",
    "            \n",
    "            # Compute cosine similarity\n",
    "            similarity = cosine_similarity(avg_library_embedding, book_embedding)\n",
    "            scores[str(book_id)] = similarity\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    ranked_books = sorted(\n",
    "        [(book_id, score) for book_id, score in scores.items()],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    return ranked_books[:k]\n",
    "\n",
    "def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "query = \"mystery thriller with plot twists\"\n",
    "recommendations = get_sbert_recommendations(\n",
    "    query=query,\n",
    "    book_embeddings_df=book_embeddings_df,\n",
    "    sbert_embeddings_df=sbert_embeddings_df,\n",
    "    k=10\n",
    ")\n",
    "\n",
    "# Print recommendations\n",
    "for book_id, score in recommendations:\n",
    "    print(f\"Book ID: {book_id}, Similarity Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules Based Filtering\n",
    "\t1.\tFilters out duplicates and already-read books\n",
    "\t2.\tBoosts diversity across genres and authors via a simple MMR-style re-rank\n",
    "\t3.\tLeaves you with a cleaned, diversified list (~K=50) to feed into your\n",
    "    cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_candidates(\n",
    "    candidates: List[str], \n",
    "    book_meta: dd.DataFrame, \n",
    "    user_history: Set[str]\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    1) Remove books the user already read.\n",
    "    2) Remove duplicates by normalized title.\n",
    "    \"\"\"\n",
    "    seen_titles = set()\n",
    "    out = []\n",
    "    for b in candidates:\n",
    "        if b in user_history:\n",
    "            continue\n",
    "        # Get title from dask dataframe\n",
    "        title = book_meta[book_meta['item_id'] == int(b)]['title'].compute().iloc[0].lower().strip()\n",
    "        if title in seen_titles:\n",
    "            continue\n",
    "        seen_titles.add(title)\n",
    "        out.append(b)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr_diversify(\n",
    "    candidates: List[str],\n",
    "    book_meta: dd.DataFrame,\n",
    "    initial_scores: Dict[str, float],\n",
    "    k: int = 50,\n",
    "    lambda_param: float = 0.7\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Maximal Marginal Relevance for genre/author diversity.\n",
    "\n",
    "    - initial_scores[b]: the rule-based or CF/SBERT score for b\n",
    "    - book_meta[b]['genres'] & ['authors'] are lists\n",
    "    - k: target number of books to pick\n",
    "    - lambda_param: trade-off between relevance vs. diversity\n",
    "    \"\"\"\n",
    "    # precompute embeddings as sets\n",
    "    rep = {}\n",
    "    for b in candidates:\n",
    "        rep[b] = set(book_meta[b].get('genres', [])) | set(book_meta[b].get('authors', []))\n",
    "    \n",
    "    selected = []\n",
    "    # pick the highest-scored book first\n",
    "    first = max(candidates, key=lambda b: initial_scores.get(b, 0))\n",
    "    selected.append(first)\n",
    "    \n",
    "    # remaining pool\n",
    "    pool = set(candidates) - {first}\n",
    "    \n",
    "    # MMR loop\n",
    "    while pool and len(selected) < k:\n",
    "        mmr_scores = {}\n",
    "        for b in pool:\n",
    "            relevance = initial_scores.get(b, 0)\n",
    "            # diversity = max similarity with any already-selected\n",
    "            sim_to_sel = max(\n",
    "                len(rep[b].intersection(rep[s])) / len(rep[b].union(rep[s])) \n",
    "                if rep[b] and rep[s] else 0\n",
    "                for s in selected\n",
    "            )\n",
    "            mmr_scores[b] = lambda_param * relevance - (1 - lambda_param) * sim_to_sel\n",
    "        # pick best\n",
    "        best = max(mmr_scores, key=mmr_scores.get)\n",
    "        selected.append(best)\n",
    "        pool.remove(best)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_and_diverse_rerank(\n",
    "    raw_candidates: List[str],\n",
    "    book_meta: dd.DataFrame,\n",
    "    user_history: Set[str],\n",
    "    base_scores: Dict[str, float],\n",
    "    final_k: int = 50\n",
    ") -> List[str]:\n",
    "    # 1) Hard filter\n",
    "    clean = filter_candidates(raw_candidates, book_meta, user_history)\n",
    "\n",
    "    # 2)  Apply simple heuristics to adjust base_scores to boost recent publications\n",
    "    for b in clean:\n",
    "        base_scores[b] += 0.01 * (book_meta[b]['pub_year'] - 2000)\n",
    "\n",
    "    # 3) Diversify via MMR\n",
    "    diversified = mmr_diversify(clean, book_meta, base_scores, k=final_k)\n",
    "\n",
    "    return diversified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain final candidates for cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw = cf_candidates + sbert_candidates\n",
    "user_hist = user_library\n",
    "# Weighting can be altered\n",
    "scores = {b: cf_score[b] + 0.5*sbert_score[b] for b in raw}\n",
    "top50 = rule_and_diverse_rerank(raw, reduced_books_df, Set(user_hist), scores, final_k=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Encoder Reranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
